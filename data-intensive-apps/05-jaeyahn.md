# Part2 분산데이터
1부에서는 단일 장비에서 데이터를 저장할 때 적용하는 데이터 시스템 측면을 살펴보았다.

2부에서는 여러 장비가 관여하는 경우에 대해서 다룬다.

여러 장비가 관여해야 하는 이유는 무엇일까? 그 이유는 다음과 같다.

### 확장성
데이터 볼륨, 읽기/쓰기 부하가 단일 장비에서 다룰 수 있는 양보다 커지는 경우 부하를 여러 장비로 분산한다.

### 내결함성/고가용성
장비 하나가 죽더라도 다른 장비가 존재하면 애플리케이션이 계속해서 동작할 수 있다.

### 지연 시간 
전 세계에 사용자가 있는 경우 사용자와 지리적으로 가까운 곳의 데이터센터에서 서비스를 제공하기 위해 전 세계 다양한 곳에 서버를 둘 필요가 있다. 이를 통해 서비스 지연 시간을 단축시킨다.


## 고부하로 확장 (수직 확장과 수평 확장)
수직 확장(scale up)

- 더 강력한 장비를 사용하는 것
- 많은 CPU, 메모리 칩, 디스크를 하나의 운영체제로 결합한다.
- 빠른 상호 연결로 모든 CPU가 메모리나 디스크의 모든 부분에 접근한다.

### 공유 메모리 아키텍처
- 모든 구성 요소를 단일 장비로 다룬다.
- 비용 대비 성능 측면에서 가성비가 좋지 않다.
- 제한적인 내결함성 제공 : 하이엔드 장비는 핫 스왑이 가능한 구성요소가 있다. (핫스왑 기능이란 장비를 중단시키지 않고, 디스크 메모리, CPU 교체 를 할 수 있는 뜻)
- 지리적으로 단일로 제한된다.

### 공유 디스크 아키텍처
- 독립적인 CPU, RAM을 탑재한 여러 장비를 사용
- 그러나 디스크는 공유한다.
- 각 장비는 고속 네트워크로 연결된다.
- 일부 데이터 웨어하우스 작업 부하에 사용된다.
- 잠금 경합과 오버헤드 등으로 인해 확장성에 제한이 있다.

## 수평 확장(scale out)
### 노드
- 데이터베이스 소프트웨어를 수행하는 각 장비 혹은 가상 장비
- 각 노드는 CPU, RAM, 디스크를 독립적으로 사용
- 노드 간의 코디네이션은 네트워크를 사용하여 소프트웨어 수준에서 수행된다.

### 비공유 아키텍처
- 특별한 하드웨어를 필요로 하지 않음 → 가성비를 갖춘 시스템을 사용할 수 있다.
- 여러 지리적인 영역에 데이터를 분산한다.
- 사용자 지연 시간을 줄일 수 있다.
- 전체 데이터 센터의 손실을 줄일 수 있다.


주의할 점
 → 이 장에서 다루는 이유
분산 시스템에서 발생하는 제약 조건과 트레이드오프가 존재
부가적인 애플리케이션 복잡도를 야기함
데이터의 분산 방법
-> 복제, 파티셔닝 

복제 -> 같은 데이터를 중복으로 공유
파티셔닝 -> 큰 데이터베이스를 파티션이라는 작은 서브셋으로 나누고 각 파티션은 각기 다른 노드에 할당(샤딩)이라고 함 -> 6장!

복제와 파티션은 이분법적으로 분리되지 않는다. 같이 활용된다.

데이터베이스는 두개의 파티션으로 나뉘고 각 파티션은 두개의 복제본을 는다.

<img width="714" alt="image" src="https://user-images.githubusercontent.com/8626130/192932883-46f77986-0cfa-48ca-918a-28d4d28b91ba.png">


---

# 05장. 복제
## 복제와 필요한 이유
- 복제란 네트워크로 연결된 여러 장비에 동일한 데이터의 복사본을 유지하는 것

복제가 필요한 이유는 다음과 같다.

1. 지리적으로 사용자와 가깝게 데이터를 유지 → 지연시간 단축
2. 시스템 일부에 장애 발생해도 지속적으로 동작 → 내결함성, 고가용성
3. 읽기 질의를 제공하는 장비의 수 확장 → 읽기 처리량 증가

> Q) 복제는 왜 어려운가?
> A) 데이터가 변경되기 때문. 복제에서 오는 어려움은 복제된 데이터의 변경 처리와 관련이 있다.

---

## 복제를 위한 방법

1. 단일 리더(single-leader)
2. 다중 리더(multi-leader)
3. 무 리더..(다같이 리더) (leaderless)

각 알고리즘은 장단점이 있음

## 리더와 팔로워

__복제 서버(replica)__ : 데이터 베이스의 복사본을 저장하는 각 노드

> Q. 모든 복제 서버에 모든 데이터가 있다는 사실을 어떻게 보장할까?
> A. 일반적인 해결방법 : 리더 기반 복제(leader-based replication)

<img width="699" alt="image" src="https://user-images.githubusercontent.com/8626130/192932989-7f04d54c-3522-4751-b15b-bab9f3cb093a.png">

### 리더 기반 복제(leader-based replication)
= 마스터 슬레이브 복제(master slave replication), 능동/수동 복제(active/passive replication)
리더(leader)

- 마스터, 프라이머리(primary)
클라이언트의 쓰기, 읽기 요청을 처리 쓰기 기록 후 팔로워에게 이를 전달

- 팔로워(follower) : 읽기 복제 서버(read replica), 슬레이브, 2차(secondary), 핫 대기(hot standby)
리더가 보낸 데이터 변경 로그, 변경 스트림을 전달 받아 데이터 복제본을 갱신
클라이언트의 읽기 요청 만을 처리
RDBMS, NoSQL, 메시지 브로커 등에 사용

### 동기식 대 비동기식 복제
복제가 동기식으로 발생하는지, 비동기식으로 발생하는 지는 복제 시스템에서 중요한 세부사항이다.

<img width="692" alt="image" src="https://user-images.githubusercontent.com/8626130/192933084-f202828b-b772-4d67-ab9f-8e7b036c18e7.png">

#### 동기식 복제

- 팔로워1의 경우

리더가 팔로워의 쓰기 수신에 대한 응답을 확인하기 위해 대기한다.
확인이 끝나면 사용자에게 성공을 보고 후 해당 쓰기를 보여준다.

이 방식의 장단점은 다음과 같다.
- 리더와 팔로워의 일관성(최신 데이터)을 보장한다.
- 팔로워가 (죽거나 네트워크 등의 문제로)응답하지 않을 시 쓰기가 처리될 수 없다.
- 리더는 모든 쓰기를 차단(block)하고 팔로워가 사용가능할 때 까지 기다려야 한다.

#### 비동기식 복제

- 팔로워2의 경우

리더가 팔로워의 쓰기 수신에 대한 응답을 기다리지 않는다.
일관성은 떨어지지만, 사용자 응답 지연 시간이 적고 고가용성 제공
동기식, 비동기식을 바탕으로 한 복제 구성 방식에는 다음과 같은 방식이 있다.

#### 반동기식(semi-synchronous)
모든 팔로워가 동기식 복제 방식을 사용할 수는 없다. 하나의 노드만 고장나도 전체 시스템이 마비.

- 팔로워 하나는 동기식, 나머지는 비동기 식으로 구성하는 것을 의미
- 동기식 팔로워가 사용 불가 시 → 다른 비동기 팔로워가 동기식으로 동작
- 적어도 두 노드(리더, 동기식 팔로워)에 데이터의 최신 복사본이 존재

> 완전한 비동기식 리더 기반 복제 방식에서 일반적으로 선택

이 방식의 장단점은 다음과 같다.

- 리더가 잘못되고 복구 불가능한 경우 팔로워에 복제되지 않은 쓰기는 유실
- 클라이언트가 어떤 쓰기를 확인했어도 해당 쓰기의 지속성을 보장할 수 없음
- 모든 팔로워가 잘못되어도 리더가 쓰기 처리를 계속할 수 있다.

내구성이 약하다는 단점에도 불구하고 다음과 같은 조건 하에 많이 사용된다.
- 많은 팔로워가 존재하는 경우
- 노드가 지리적으로 분산된 경우

## 새로운 팔로워 설정
새로운 팔로워 설정이 필요한 경우가 있다.
- 복제 서버의 수를 늘려야 하는 경우
- 장애 노드를 대체하는 경우

Q. 새로운 팔로워의 추가 설정은 어떻게 진행해야 할까?

A1. 데이터 파일을 복사한다. (X)
- 복사하는 와중에도 클라이언트의 쓰기 요청은 계속 발생한다. 파일의 복사본은 유효하지 않은(out-of-date) 데이터를 포함한다.

A2. 일관성을 보장하기 위해 데이터베이스를 잠가 잠시동안 쓰기를 막는다. (X)
- 고가용성 목표에 부합하지 않는다.

A3. 다음과 같이 중단 없이 팔로워 설정을 수행한다. (O)
1. 데이터베이스를 잠그지 않고 리더의 데이터베이스 스냅샷을 가져온다.
2. 스냅샷을 새로운 팔로워 노드에 복사한다.
3. 이후 팔로워는 리더에 연결해 스냅샷 이후 발생한 모든 데이터 변경 내역을 요청한다.
4. 요청한 데이터 변경 미처리분(backlog)을 모두 처리하면 팔로워가 리더를 따라잡았다고 말한다.
5. 이제 팔로워는 리더의 데이터 변경을 처리할 수 있다.

### 노드 중단 처리
시스템의 모든 노드는 다음과 같은 사유로 중단될 수 있다.

## 장애

계획된 유지보수
- ex. 커널 보안 패치를 위한 장비 리부팅

단일 노드는 중단 되더라도 전체 시스템은 중단되지 않고 서비스되어야 한다.
개별 노드의 장애애도 전체 시스템이 잘 동작하고 노드 중단의 영향을 최소화하는 것이 목표다.
리더 기반 복제에서 고가용성은 어떻게 달성할 수 있을까?

### 팔로워 장애: 따라잡기 복구 팔로워에 장애가 나는 경우. → 팔로워가 리더를 따라잡음으로써 복구한다.

1. 팔로워는 리더로부터 수신한 데이터 변경 로그를 로컬 디스크에 보관
2. 팔로워가 죽거나, 네트워크 중단 등으로 복구하는 경우 로그를 이용하여 복구를 시작할 수 있다.
3. 로그에서 마지막으로 처리된 트랜잭션을 찾는다.
4. 해당 트랜잭션 이후의 데이터 변경 내역을 리더에 요청
5. 요청한 변경 내역을 모두 적용하면 리더를 따라잡아 복구가 완료된다.


### 리더 장애: 장애 복구(failover) 장애 복구 과정은 다음과 같이 진행한다.

1. 팔로워 중 하나를 새로운 리더로 승격
2. 클라이언트는 새로운 리더로 쓰기를 전송해야 함. → 재설정이 필요하다.
3. 다른 팔로워는 새로운 리더로부터 데이터 변경을 소비하기 시작
4. 수동 또는 자동으로 진행한다.

#### 자동 장애 복구 과정
자동 장애 복구는 다음과 같이 진행한다.

1. 리더가 장애인지 판단한다.
 - 판단할 수 있는 확실한 방법은 없음 → 보통 타임아웃을 사용
 - 노드 간 메시지를 주고 받고 일정시간 응답하지 않는 노드는 죽은 것으로 간주
 - 예외도 존재, 리더가 계획된 유지 보수를 위해 의도적으로 중단되는 경우

2. 새로운 리더를 선택한다.
 - 복제 노드들이 새로운 리더를 선출
 - 또는 제어 노드(controller node)가 새로운 리더를 임명
 - 최신 데이터 변경사항을 가진 복제 서버가 새로운 리더의 가장 적합한 후보로 지목된다.

3. 새로운 리더 사용을 위해 시스템을 재설정한다.
 - 클라이언트의 쓰기 요청, 팔로워의 데이터 변경 로그 재설정
 - 이전 리더가 복구되는 경우 이전 리더가 새로운 리더를 인식하고 자신은 팔로워가 된다.

#### 자동 장애 복구 과정에서의 위험
다양한 위험이 존재한다. 그래서 수동 장애 복구 방식을 선호하는 운영팀도 존재한다.

##### case1 내구성을 보장하지 않음
- 비동기식 복제 사용 시 새로운 리더는 이전 리더의 최신 쓰기 중 일부를 받지 못했을 수 있음
- 이전 리더가 다시 클러스터에 추가되면 해당 최신 쓰기 내역은 어떻게 해야 하는가?
- 새로운 리더가 이와 충돌하는 쓰기를 받았을 수 있음 → 해당 쓰기를 폐기하는 것이 일반적
- 클라이언트 입장에서 내구성을 신뢰할 수 없음.

##### case2 쓰기를 폐기하는 방식의 경우 DB 외부의 다른 저장소 시스템에서 DB 내용에 맞춰 조정되는 경우 문제 발생
- Github 실제 사례, MySQL과 Redis 간 데이터 불일치
- MySQL의 팔로워가 리더로 승격. 이 팔로워가 이전 리더의 쓰기 내역을 완벽히 갱신하지 못함


##### case3 스플릿 브레인(Split Brain)
- 특정 결함 시나리오에서 두 노드가 자신이 리더라고 인식
- 두 리더가 각자 쓰기 요청을 처리하기 때문에 쓰기 충돌이 발생
- 쓰기 충돌을 해소하지 못하면 데이터가 유실 또는 오염된다.
- 둘 이상의 리더가 감지되면 하나를 종료하는 메커니즘도 있으나 잘못 설계 시 둘 모두가 종료될 수 있음
- 죽었다고 판단하기에 적절한 타임아웃 값을 정하기가 어렵다.

##### etc 
타임아웃이 길면 → 복구에 너무 오랜 시간이 소요
타임아웃이 짧으면 → 불필요한 장애복구 발생
노드의 응답시간 조차 일시적인 부하 급증, 네트워크 문제 등으로 일정할 수 없다.
시스템이 높은 부하, 네트워크 문제와 씨름 중인 경우 불필요한 장애 복구는 상황을 악화시킬 수 있음.


## 복제 로그 구현
리더 기반 복제는 내부적으로 어떻게 동작하는가? 다음과 같은 다양한 복제 방법을 사용한다.

### 구문(Statement) 기반 복제

요청받은 구문을 기록하고 쓰기를 실행한 다음 구문을 팔로워에게 전송
- RDB : INSERT, UPDATE, DELETE …

비결정적인 요인에 의해 복제가 깨질 수 있다.
- NOW(), RAND() 등은 복제 서버마다 다른 값을 생성할 가능성이 존재
- 자동증가 컬럼을 사용하거나, 기존 데이터에 의존하는 경우(WHERE) 정확히 같은 순서로 실행되어야 함
순서가 다르면 구문의 효과가 다를 수 있음 → 동시에 여러 트랜잭션이 수행되는 것을 제한한다.
부수효과를 가진 구문의 경우 부수효과가 완벽히 결정적이어야 모든 팔로워에서 그 효과도 동일하다.

- 트리거, 스토어드 프로시저, 사용자 정의 함수
- 대안은 리더가 구문 기록 시 비결정적 함수 호출을 고정 값을 반환하도록 대체하는 것
- 여러 에지 케이스가 있어 현재는 다른 방식을 선호
- MySQL은 비결정성 요인이 있으면 로우 기반 복제 방식으로 변경

### 쓰기 전 로그(WAL, write-ahead log) 배송

- 일반적으로 데이터베이스의 모든 쓰기는 로그에 기록이 된다.
- 리더가 로그를 팔로워에게 전송하고, 팔로워는 이 로그를 처리함으로써 복제한다.
- 로그는 제일 저수준의 데이터를 기술함
- 디스크 블록에서 어떤 데이터를 변경했는 지와 같은 상세 정보 포함
- 복제 프로세스가 저장소 엔진과 밀접하게 연관된다.
- 리더와 팔로워가 동일한 소프트웨어 버전에서 실행되어야 한다.
- 소프트웨어 업그레이드 시 중단 시간이 필요하다.
- PostgresQL, Oracle

### 논리적(로우 기반) 로그 복제

- 로그를 저장소 엔진과 분리하기 위한 대안으로 복제와 저장소 엔진에 각기 다른 로그 형식을 사용한다. 
- (Change Data Capture) -> 11장!
![image](https://user-images.githubusercontent.com/8626130/192936405-41934893-ccd5-45de-91cc-8640e1276117.png)


### 트리거 기반 복제
지금까지 설명한 복제 방식은 애플리케이션의 관여 없이 DB 시스템에 의해 구현되었다.

때로는 복제 방식에 유연성이 요구되며 애플리케이션이 관여할 필요가 있다.

Oracle의 GoldenGate : 데이터베이스 로그를 읽어 애플리케이션이 데이터를 변경할 수 있도록 함
많은 RDBMS : 트리거, 스토어드 프로시저 제공

ex. Oracle의 Databus, PostgresQL의 Bucardo
트리거 방식의 장단점은 다음과 같다.

- 트리거 기반 복제는 다른 복제 방식보다 많은 오버헤드가 있다.
- 그리고 데이터베이스에 내장된 복제보다 버그나 제한 사항이 더 많이 발생한다.
- 그럼에도 불구하고 유연성 때문에 매우 유용하다.

![image](https://user-images.githubusercontent.com/8626130/192936687-05be47e4-e6e4-4fdf-bac3-ce92b75fa8b7.png)

---

## 복제 지연 문제
읽기 확장(read-scaling) 아키텍처
