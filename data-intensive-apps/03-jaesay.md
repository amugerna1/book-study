# 3장. 저장소와 검색

적합한 저장소 엔진을 선택할 수 있도록 저장소 엔진이 내부에서 수행되는 작업(저장/검색)을 간단하게 살펴보자..

# 제일 간단한 데이터 베이스

- CSV 파일과 같이 매 라인마다 쉽표로 구분된 키-값 쌍으로 포함된 텍스트 파일
- 추가로 다뤄야 할 사항은 많지만..append-only 데이터 파일인 로그의 기본원리와 유사
- 데이터베이스에 많은 레코드가 있으면 성능이 좋지 않음 (O(n))

![스크린샷 2022-08-31 오후 10 59 42](https://user-images.githubusercontent.com/19777164/187736564-5a932d23-e82e-42b5-996f-40b4e4b239a3.png)

# 색인

데이터베이스에서 특정키의 값을 효율적으로 찾기 위해서는 index를 사용한다.

다양한 index 구조를 살펴보고 비교해보자.

## 로그 구조화 색인

### 해시 색인

![스크린샷 2022-08-31 오후 11 06 28](https://user-images.githubusercontent.com/19777164/187736735-5df8cb5b-77e4-4620-811b-4c02be98f9f4.png)

디스크 상의 데이터를 색인하기 위한 인메모리 데이터 구조를 생각해보자.(인메모리 데이터 구조를 위한 해시 맵은 레퍼런스 참고)

- 키를 데이터 파일의 바이트 오프셋에 매핑해 메모리 해시맵을 유지
- 단순히 파일에 추가하는 방식으로 데이터 저장소 구성
- 파일에 새로운 키-값 쌍을 추가할 때마다 방금 기록한 데이터의 오프셋을 반영하기 위해 해시맵 갱신
- 값 조회 시 해시맵을 사용해 데이터파일에서 오프셋을 찾아 해당 위치를 구하고 값을 읽음

매우 단순해보이지만 실제로 많이 사용하는 방법이다.(e.g. 비스캐스크(Bitcask)(리악(Riak)의 기본 저장소 엔진) 비트캐스크는 해시 맵을 전부

지금까지 설명한 것처럼 파일에 항상 추가만 한다면 결국 디스크 공간이 부족해진다. 특정 크기의 세그먼트(segment)로 로그를 나눈 방식를 나누는 방식이 좋은 해결책이다.

![스크린샷 2022-08-31 오후 11 25 40](https://user-images.githubusercontent.com/19777164/187736808-002fc9f3-38f3-4f2d-abbf-5a5700ee2c60.png)

- 특정 크기에 도달하면 세그먼트 파일을 닫고 새로운 세그먼트 파일에 이후 쓰기를 수행
- 세그먼트 파일에 대해 중복된 키를 버리고 각 키의 최신 갱신 값만 유지(compaction)
    - compaction은 백그라운드에서 수행
- 컴팩션을 수행하는 동안 이전 세그먼트 파일을 사용해 읽기와 쓰기 요청 처리를 수행하고 병합이 끝난 이후에는 읽기 요청은 새로 병합한 세그먼트를 사용하게끔 전환하고 이전 세그먼트 파일 삭제

하지만 해시 테이블 색인 또한 제한 사항이 있다.

- 해시테이블은 메모리에 저장해야 하므로 키가 너무 많으면 문제
- 해시 테이블은 범위질의(range query)에 효율적이지 않다.

### SS테이블과 LSM 트리

이전 요구사항에서 일련의 키-값 쌍을 키로 정렬해보자. 이처럼 키로 정렬된 형식을 Sorted String Table 또는 짧기 SS테이블이라고 부른다.

![스크린샷 2022-08-31 오후 11 49 19](https://user-images.githubusercontent.com/19777164/187736885-08e6dccb-f47b-44b1-9497-cac6ff3292c4.png)

![스크린샷 2022-08-31 오후 11 49 07](https://user-images.githubusercontent.com/19777164/187736903-7b4ea5f7-8d49-4c8c-863c-958306687f83.png)

- 새그먼트들은 키로 정렬하기 위해 쓰기가 들어오면 balanced tree 데이터 구조(a.g. red-black tree, AVL tree)에 추가 (멤테이블(memtable))
    - 파일에서 특정 키를 찾기 위해 더는 메모리에 모든 키의 색인을 유지할 필요 없고 일부 키에 대한 오프셋을 알려주는 인메모리 색인만 필요
- 멤테이블이 보통 수 메가바이트 정도의 임곗값보다 커지면 SS테이블 파일로 디스크에 기록하고 SS테이블을 기록하는 동안 쓰기는 새로운 멤테이블 인스턴스에 기록
    - 레코드들을 블록으로 그룹화하고 쓰기 전에 압축
- 읽기 요청을 제공하려면 먼저 멤테이블에서 키를 찾고 디스크 상의 가장 최신..그 다음 최신 .. 세그먼트에서 찾음
- 백그라운드에서 여러 SS테이블 세그먼트를 병합하고 각 키의 최신 값만 유지(병합정렬과 유사)
- 여러 SS테이블 세그먼트를 병합하고 각 키의 최신 값만 유지(병합정렬과 유사)

## B Tree

B 트리는 1970년대에 등장했다. 10년도 안 돼 “보편화적인 색인 구조"라 불렸다. 여전히 대부분의 관계형 데이터베이스에서 표준 색인 구현으로 B 트리를 사용할 뿐 아니라 많은 비관계형 데이터베이스에서도 사용한다.

- 키로 정렬된 키-값 쌍 유지
- 4KB 크기(때로는 더 큰)의 고정 크기 블록이나 페이지로 나누고 한번에 하나의 페이지에 읽기 또는 쓰기
    - 디스크가 고정 크기 블록으로 배열되기 떄문에 이런 설계는 근본적으로 하드웨어와 조금 밀접한 관련이 있다.
- 각 페이지는 주소나 위치를 이용해 식별 가능(포인터와 비슷하지만 메모리 대신 디스크에 있음)

### 검색

![스크린샷 2022-09-01 오전 12 06 16](https://user-images.githubusercontent.com/19777164/187736965-0a5429e6-d717-4bd4-ba75-9085b3d6720e.png)

루트부터 시작하여 경계 사이의 페이지 참조를 따라간다. 하위 페이지는 좀 더 작은 범위로 나눈 페이지이기 떄문에 최종적으로는 개별 키를 포함하는 리프페이지에 도달한다. 대부분의 데이터베이스는 B 트리의 깊이가 3이나 4단계 정도면 충분하므로 검색하려는 페이지를 찾기 위해 많은 페이지 참조를 따라가지 않아도 된다(분기 계수 500의 4KB 페이지의 4단계 트리는 256TB (=500^4 * 4096B)까지 저장할 수 있다.)

### 추가

![스크린샷 2022-09-01 오전 12 15 32](https://user-images.githubusercontent.com/19777164/187737036-b0e38659-557f-40a0-99b3-dd967f320b66.png)

새로운 키를 추가하려면 새로운 키를 포함하는 범위의 페이지를 찾아 해당 페이지에 키와 값을 추가한다. 새로운 키를 수용한 페이지에 충분한 여유 공간이 없다면 페이지 하나를 반쯤 채워진 페이지 둘로 나누고 상위 페이지가 새로운 키 범위의 하위 부분들을 알 수 있게 갱신한다. 이 알고리즘은 트리가 계속 균형을 유지하는 것을 보장한다. (O(log n))
# 색인 (Index)

## 색인 구조

### 기본키 색인 (Primary key index)

기본키로 관계형 테이블에서 하나의 로우를, 문서 데이터베이스에서는 하나의 문서를, 그래프 데이터베이스에서는 하나의 정점을 고유하게 식별할 수 있다.

### 보조 색인 (Secondary index)

같은 테이블에 다양한 보조 색인을 생성할 수 있다.

보조 색인은 보통 효율적으로 조인을 수행하는 결정적인 역할을 한다.

같은 키를 가진 많은 로우(문서, 정점)이 있을 수 있다. 이를 해결하는 방법으로는 색인의 각 값에 일치하는 로우 식별자 목록을 만드는 방법과 로우 식별자를 추가해 각 키를 고유하게 만드는 경우가 있다. 어느쪽이든 보조색인으로 B 트리와 로그 구조화 색인 둘 다 사용할 수 있다.

### 색인 안에 값 저장하기

색인에서 키는 질의가 검색하는 대상이다.

색인에서 값은 실제 로우(문서, 정점)이거나 다른 곳에 저장된 로우를 가리키는 참조이다.

다른 곳에 저장된 로우를 가리키는 참조일 때 실제 로우가 저장된 곳을 힙파일(heap file)이라고 한다.  힙파일은 특정 순서 없이 데이터를 저장한다. 덕분에 여러 보조 색인이 존재할 때 데이터 중복을 피할 수 있다.

색인에서 힙파일로 다시 이동하는 일은 읽기 성능에 불이익이 너무 많기 때문에 어떤 상황에서는 색인 안에 바로 색인된 로우를 저장하는 편이 바람직하다. 이를 클러스터드 색인(clustered index라고 한다.)

클러스터드 색인과 비클러스터드 색인 사이의 절충안을 커버링 색인(covering index)이라고 한다. 이 색인은 색인 안에 테이블 컬럼 일부를 저장한다.

클러스터드 색인과 커버링 색인은 추가적인 저장소 필요, 쓰기과정에서 오버헤드, 애플리케이션에서 복제간 불일치 파악의 어려움, 트랜잭션 보장 등의 단점도 있다.

### 다중컬럼 색인 (Multi-column indexes)

다중컬럼 색인의 가장 일반적인 유형은 결합 색인(concatenated index)이라고 한다.

결합 색인은 하나의 키에 여러 필드를 단순히 결합하고 필드가 연결되는 순서는 색인 정의에 명시한다. (e.g (성, 이름) → 전화번호)

다차원 색인(Multi-dimensional indexes)은 한번에 여러 컬럼에 질의하는 조금 더 일반적인 방법이다. 1차원 색인(one- dimensional index)을 사용하면 첫번째 순서 컬럼으로 모든 색인을 스캔한 다음 다음 순서 컬럼으로 필터링해야 하지만 다차원 색인은 여러 컬럼을 동시에 범위를 줄일 수 있다.

### 전문 검색과 퍼지 색인 (**Full-text search and fuzzy indexes)**

철자가 틀린 단어와 유사한 키와 같이 애매모호한(fuzzy) 질의를 위해 사용한다. 예를 들어 전문 검색 엔진은 일반적으로 특정 단어를 검색할 때 해당 단어의 동의어로 질의를 확장하는 등 다양한 기능을 제공한다.

## 인메모리 데이터베이스 (in-memory database)

디스크에 저장하는 것은 메인메모리에 비해 다루기가 어렵지만 지속성과 가격면에서 장점이 있다.

램 가격이 저렴해지고 특수 하드웨어, 로그 기록, 디스크에 스냅샷 저장 등 지속성을 달성하는 방법도 생겼다. 

인메모리 데이터베이스의 성능 장점은 디스크에서 읽지 않아도 된다는 사실 때문은 아니다.

성능 외에도 인메모리 데이터베이스는 디스크 기반 색인으로 구현하기 어려운 데이터 모델을 제공한다.

인메모리 데이터베이스 아키텍처가 디스크 중심 아키텍처에서 발생하는 오버헤드 없이 가용한 메모리 보다 더 큰 데이터셋을 지원하게 끔 확장할 수 있다. (안티캐싱 참고)

# OLTP/OLAP

보통 애플리케이션은 색인을 사용해 일부 키에 대한 적은 수의 레코드를 찾는다. 레코드는 사용자 입력을 기반으로 삽입되거나 갱신된다. 이런 애플리케이션은 대화식이기 때문에 이 접근 패턴을 온라인 트랜잭션 처리(online transaction processing, OLTP)라고 한다.

그러나 데이터베이스를 데이터 분석(data analytic)에도 점점 더 많이 사용하기 시작했다. 데이터 분석은 트랜잭션과 접근 패턴이 매우 다르다. 원시 데이터를 반환하는 게 아니라 많은 수의 레코드를 스캔해 집계를 계산해야 한다. 이런 데이터베이스 사용 패턴을 처리와 구별하기 위해 온라인 분석처리(online analytic processing, OLAP)라고 부른다.

## 데이터 웨어하우스(data warehouse)

![스크린샷 2022-09-01 오전 12 38 14](https://user-images.githubusercontent.com/19777164/187737088-2b420a83-4972-451e-8624-f87ca75e5183.png)

데이터 웨어하우스는 분석가들이 OTLP 작업에 영향을 주지 않고 마음껏 질의할 수 있는 개별 데이터베이스이다. 데이터는 OLTP 데이터베이스에서 추출(extract)하고 분석 친화적인 스키마로 변환(transform)하고 깨끗하게 정리한 다음 데이터 웨어하우스에 적재(load)한다.(ETL)

## 분석용 스키마: 별모양 스키마와 분꽃송이 모양 스키마

**별모양 스키마**

많은 데이터 웨어하우스는 별 모양 스키마(star schema)(차원 모델링(dimensional modeling)이라고도 함)로 알려진 상당히 정형화된 방식을 사용한다.(분석에서는 데이터 모델의 다양성이 훨씬 적음)

![스크린샷 2022-09-01 오전 12 48 56](https://user-images.githubusercontent.com/19777164/187737178-420646fa-c197-4059-8803-b424713821aa.png)

- 사실 테이블(fact table): 각 로우는 특정 시각에 발생한 이벤트에 해당한다.(e.g. 고객의 제품 구매) 사실 테이블의 일부 컬럼은 제품이 판매된 가격과 공급자로부터 구매한 비용과 같은 속성이다. 나머지 다른 컬럼들은 차원 테이블을 가리키는 외래키 참조다.
- 차원테이블(dimension table): 이벤트의 속성인 누가, 언제, 어디서, 무엇을, 어떻게, 왜를 나타낸다. (e.g. 판매된 제품(dim_product))

**눈꽃송이 모양 스키마(snowflake schema)**

별 모양 스키마의 변형이며 차원이 하위차원으로 더 세분화된다. 예를 들어 브랜드와 제품 범주의 테이블을 분리할 수 있고 dim_product 테이블의 각 로우는 dim_product 테이블에 문자열로 브랜드와 범주를 저장하는 대신 외래키로 참조할 수 있다. 눈꽃송이 스키마는 별 모양 스키마보다 더 정규화됐지만 분석가들이 별 모양 스키마를 작업하기 더 쉽다는 이유로 선호한다.

## 컬럼지향 저장소

사실 테이블에는 엄청난 개수의 로우와 페타바이트 데이터가 있기 떄문에 모든 값을 하나의 로우에 함께 저장하지 않는 대신 각 컬럼 별로 모든 값을 함께 저장한다. 각 컬럼을 개별 파일에 저장하면 질의에 사용되는 컬럼만 읽고 분석하면 된다.

![스크린샷 2022-09-01 오전 1 04 14](https://user-images.githubusercontent.com/19777164/187737241-9fab0a30-0754-4af0-9459-e1bbf0fff7e3.png)

![스크린샷 2022-09-01 오전 1 03 12](https://user-images.githubusercontent.com/19777164/187737286-6308f0e8-c4c7-43a1-ac62-4c8e78f80a50.png)

### 컬럼압축

질의에 필요한 컬럼을 디스크에서 읽어 적재하는 작업 외에도 데이터를 압축하면 디스크 처리량을 줄일 수 있다. 컬럼 지향 저장소는 대개 압축에 적합하다. 다양한 종류의 데이터에 대한 다양한 압축 스키마가 있다. (많은 값이 반복해서 나타남 ⇒ 비트맵 부호화)

### 순서정렬

이전의 SS테이블에서 했던 것처럼 순서를 도입해 이를 색인 메커니즘으로 사용할 수 있다. 공통 질의에 대한 지식을 사용해 테이블에서 정렬해야 하는 컬럼을 선택할 수 있다.

### 쓰기

요것도 LSM 트리 방식과 같다.

### 집계: 데이터 큐브(data cube)와 구체화 뷰(materialized view)

동일한 집계를 많은 다양한 질의에서 사용한다면 매번 원시데이터를 처리하는 일은 낭비이다. 데이터 웨어하우스는 읽기 비중이 크기 떄문에 질의가 자주 사용하는 일부 카운트(count)나 합(sum) 등을 캐시하는 것은 효과적일 수 있다.

**데이터 큐브**

다양한 차원으로 그룹화한 집계테이블

![스크린샷 2022-09-01 오전 1 29 58](https://user-images.githubusercontent.com/19777164/187737336-aa8c101f-4dca-4d11-b444-15be51b1eb39.png)

데이터 큐브의 단점은 원시 데이터에 질의하는 것과 동일한 유연성이 없다는 점이다. 데이터 큐브와 같은 집계 값은 특정 질의에 대한 성능 향상에만 사용한다.
